<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: opencv | kennary island]]></title>
  <link href="http://kennyyu.me/blog/categories/opencv/atom.xml" rel="self"/>
  <link href="http://kennyyu.me/"/>
  <updated>2014-03-20T00:24:12-04:00</updated>
  <id>http://kennyyu.me/</id>
  <author>
    <name><![CDATA[Kenny Yu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Pipeline for Improving Hand Tracking Accuracy]]></title>
    <link href="http://kennyyu.me/blog/2012/12/10/pipeline-for-improving-hand-tracking-accuracy/"/>
    <updated>2012-12-10T21:48:00-05:00</updated>
    <id>http://kennyyu.me/blog/2012/12/10/pipeline-for-improving-hand-tracking-accuracy</id>
    <content type="html"><![CDATA[<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/DFPg-9D46kE "></iframe></div></p>

<p>For my CS283: Computer Vision Final Project, I created an application to control Google Maps
using your hand and a webcam.</p>

<p>It uses the Chrome API to access the webcam, and frames are sent to a Tornado server that
runs the hand tracking pipeline, annotates the frame, and sends back the displacement
vector to update the view of the map. I am using OpenCV for it's Haar Cascade libraries.</p>

<p>You can <a href="https://github.com/kennyyu/cs283-project">view the code on github</a>
and setup an instance of the server locally!</p>

<p>You can also <a href="https://www.dropbox.com/s/tnyzr1qt8fmnscp/hand-tracking-pipeline.pdf">view the paper</a>
I wrote to describe the process I used in the pipeline. Below is a summary of the problem
statement and the stages in the pipeline.</p>

<h1>Problem Statement</h1>

<p>Given a poorly trained Haar Cascade Classifier (250 positive samples and 100 negative samples) to recognize hands,
this project assembles a pipeline to improve the quality of the tracking. These steps include:</p>

<ol>
<li>Face detection and removal of faces.</li>
<li>Background subtraction.</li>
<li>Use a simplified Kalman-Filter-esque technique to estimate the bounding box of the hand. This assumes that a hand moves in a smooth manner.</li>
<li>Use our hand classifier to detect the largest hand within the bounding box.</li>
<li>Compute the optical flow of points within the bounding box using Lucas-Kanade.</li>
<li>Use the optical flow and the measured position of the hand to correct our Kalman-Filter estimate.</li>
</ol>

]]></content>
  </entry>
  
</feed>
